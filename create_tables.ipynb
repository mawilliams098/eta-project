{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wrapped-conspiracy",
   "metadata": {},
   "source": [
    "# F2-F4 Table Setup \n",
    "\n",
    "Annie Williams (maw3as@virginia.edu)  \n",
    "DS 5001  \n",
    "2 May 2021  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-memorabilia",
   "metadata": {},
   "source": [
    "This notebook contains the code to create the initial F2-F4 `DOC`, `LIB`, `TOKEN`, and `VOCAB` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executed-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bizarre-medicaid",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/annewilliams/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/annewilliams/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annewilliams/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/annewilliams/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "closed-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = './source_files'\n",
    "data_out = './F2-F4_tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "realistic-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_id:    the unique id for each document, \n",
    "# book_num:  each book within the iliad / odyssey \n",
    "\n",
    "OHCO = ['doc_id', 'book_num', 'stanza_num', 'line_num', 'token_num']\n",
    "LINES = OHCO[:4]\n",
    "STANZAS = OHCO[:3]\n",
    "BOOKS = OHCO[:2]\n",
    "DOCS = OHCO[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-brass",
   "metadata": {},
   "source": [
    "## Set up initial F2 `LIB` and `DOC` tables\n",
    "* Code based on Module 4 Pipeline notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liquid-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    100: {\n",
    "        'start_line': 373,\n",
    "        'end_line': 10838,\n",
    "        'book': re.compile(r'^BOOK\\s+{}.$'.format(roman))\n",
    "    },\n",
    "    200: {\n",
    "        'start_line': 76,\n",
    "        'end_line': 14568,\n",
    "        'book': re.compile(r'^BOOK\\s+{}.$'.format(roman))\n",
    "    },\n",
    "    300: {\n",
    "        'start_line': 955,\n",
    "        'end_line': 16699,\n",
    "        'book': re.compile(r\"^THE\\s+\\w+\\-?\\w+?\\s+BOOK OF HOMER’S ILIADS$\")\n",
    "    }, \n",
    "    400: {\n",
    "        'start_line': 423,\n",
    "        'end_line': 18344,\n",
    "        'book': re.compile(r'^THE\\s+\\w+\\-?\\w+?\\s+BOOK OF HOMER’S ODYSSEYS')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuing-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_epubs(epub_list, chap_pats, OHCO=OHCO):\n",
    "    \n",
    "    my_lib = []\n",
    "    my_doc = []\n",
    "\n",
    "    for epub_file in epub_list:\n",
    "        \n",
    "        # Get ID from filename\n",
    "        doc_id = int(epub_file.split('/')[-1].split('-')[0])\n",
    "                      \n",
    "        print(\"BOOK ID\", doc_id)\n",
    "        \n",
    "        # Import file as lines\n",
    "        lines = open(epub_file, 'r', encoding='utf-8-sig').readlines()\n",
    "        df = pd.DataFrame(lines, columns=['line_str'])\n",
    "        df.index.name = 'line_num'\n",
    "        df['doc_id'] = doc_id\n",
    "        \n",
    "        # FIX CHARACTERS TO IMPROVE TOKENIZATION\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        # Get book title and put into LIB table -- note problems, though\n",
    "        book_title = re.sub(r\"The Project Gutenberg eBook( of|,) \", \"\", df.loc[0].line_str, flags=re.IGNORECASE)\n",
    "        book_title = re.sub(r\"Project Gutenberg's \", \"\", book_title, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Remove cruft\n",
    "        a = chap_pats[doc_id]['start_line'] - 1\n",
    "        b = chap_pats[doc_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]\n",
    "        \n",
    "        # Chunk by book\n",
    "        chap_lines = df.line_str.str.match(chap_pats[doc_id]['book'])\n",
    "        book_nums = [i+1 for i in range(df.loc[chap_lines].shape[0])]\n",
    "        df.loc[chap_lines, 'book_num'] = book_nums\n",
    "        df.book_num = df.book_num.ffill()\n",
    "\n",
    "        # Clean up\n",
    "        df = df.dropna(subset=['book_num']) # Remove everything before book 1\n",
    "        df = df.loc[~chap_lines] # Remove book heading lines\n",
    "        df['book_num'] = df['book_num'].astype('int')\n",
    "        \n",
    "        # Group -- Note that we exclude the book level in the OHCO at this point\n",
    "        df = df.groupby(OHCO[1:2]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "        \n",
    "        # Split into paragrpahs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'stanza_str'})\n",
    "        df.index.names = OHCO[1:3] # MAY NOT BE NECESSARY UNTIL THE END\n",
    "        df['stanza_str'] = df['stanza_str'].str.replace(r'\\n', ' ', regex=True).str.strip()\n",
    "        df = df[~df['stanza_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "        \n",
    "        # Set index\n",
    "        df['doc_id'] = doc_id\n",
    "        df = df.reset_index().set_index(OHCO[:3])\n",
    "\n",
    "        # Register\n",
    "        my_lib.append((doc_id, book_title, epub_file))\n",
    "        my_doc.append(df)\n",
    "\n",
    "    docs = pd.concat(my_doc)\n",
    "    library = pd.DataFrame(my_lib, columns=['doc_id', 'book_title', 'book_file']).set_index('doc_id')\n",
    "    print(\"Done.\")\n",
    "    return library, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "obvious-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 100\n",
      "BOOK ID 200\n",
      "BOOK ID 300\n",
      "BOOK ID 400\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "epubs = [epub for epub in sorted(glob('{}/*.txt'.format(data_in)))]\n",
    "LIB, DOC = acquire_epubs(epubs, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add some features to the LIB table because there are so few documents \n",
    "LIB[\"translator\"] = ['Butler', 'Butler', 'Chapman', 'Chapman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "micro-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_file</th>\n",
       "      <th>translator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The Iliad, by Homer\\n</td>\n",
       "      <td>./data_in/100-iliad-butler.txt</td>\n",
       "      <td>Butler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>The Odyssey, by Homer\\n</td>\n",
       "      <td>./data_in/200-odyssey-butler.txt</td>\n",
       "      <td>Butler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>The Iliads of Homer, by Homer\\n</td>\n",
       "      <td>./data_in/300-iliad-chapman.txt</td>\n",
       "      <td>Chapman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>The Odysseys of Homer, by Homer\\n</td>\n",
       "      <td>./data_in/400-odyssey-chapman.txt</td>\n",
       "      <td>Chapman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               book_title                          book_file  \\\n",
       "doc_id                                                                         \n",
       "100                 The Iliad, by Homer\\n     ./data_in/100-iliad-butler.txt   \n",
       "200               The Odyssey, by Homer\\n   ./data_in/200-odyssey-butler.txt   \n",
       "300       The Iliads of Homer, by Homer\\n    ./data_in/300-iliad-chapman.txt   \n",
       "400     The Odysseys of Homer, by Homer\\n  ./data_in/400-odyssey-chapman.txt   \n",
       "\n",
       "       translator  \n",
       "doc_id             \n",
       "100        Butler  \n",
       "200        Butler  \n",
       "300       Chapman  \n",
       "400       Chapman  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "peripheral-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stanza_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>book_num</th>\n",
       "      <th>stanza_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">100</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Jove sends a lying dream to Agamemnon, who the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chiefs in assembly, and proposes to sound the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the end they march to fight — Catalogue of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forces.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now the other gods and the armed warriors on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   stanza_str\n",
       "doc_id book_num stanza_num                                                   \n",
       "100    1        1           Jove sends a lying dream to Agamemnon, who the...\n",
       "                2           chiefs in assembly, and proposes to sound the ...\n",
       "                3           the end they march to fight — Catalogue of the...\n",
       "                4                                                     forces.\n",
       "                5           Now the other gods and the armed warriors on t..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-break",
   "metadata": {},
   "source": [
    "## Create F2 `TOKEN` table, and add F3 `pos` attribute\n",
    "\n",
    "We use NLTK this time. Note that this process takes some time, mainly because the NLTK functions are not optimized for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hidden-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.stanza_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "challenging-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(DOC, ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "responsible-observation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>book_num</th>\n",
       "      <th>stanza_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">100</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Jove, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Jove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(sends, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>sends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(a, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(lying, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(dream, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pos_tuple  pos token_str\n",
       "doc_id book_num stanza_num line_num token_num                             \n",
       "100    1        1          0        0           (Jove, NNP)  NNP      Jove\n",
       "                                    1          (sends, VBZ)  VBZ     sends\n",
       "                                    2               (a, DT)   DT         a\n",
       "                                    3           (lying, JJ)   JJ     lying\n",
       "                                    4           (dream, NN)   NN     dream"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-click",
   "metadata": {},
   "source": [
    "## Create `VOCAB` table\n",
    "\n",
    "Extract a vocabulary from the TOKEN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polish-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addressed-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKEN.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "saved-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prepared-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>ῥα</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19729</th>\n",
       "      <td>ῥοτὸς</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>ῥοᾓ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19731</th>\n",
       "      <td>ῥέω</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>ῥῶγες</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19733 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str     n  num\n",
       "term_id                    \n",
       "0                 4733    0\n",
       "1              1    48    1\n",
       "2             10     8    1\n",
       "3            100     2    1\n",
       "4           1000     1    1\n",
       "...          ...   ...  ...\n",
       "19728         ῥα     1    0\n",
       "19729      ῥοτὸς     1    0\n",
       "19730        ῥοᾓ     1    0\n",
       "19731        ῥέω     1    0\n",
       "19732      ῥῶγες     1    0\n",
       "\n",
       "[19733 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "premium-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of F2 corpus, begin F3 corpus ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-prophet",
   "metadata": {},
   "source": [
    "## Continue building on F3 by annotating `VOCAB` table \n",
    "\n",
    "I use NLTK's built in stopword list for English. \n",
    "\n",
    "The following code chunks add stop words, stems, and `pos_max`.\n",
    "\n",
    "### 1. Add Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "registered-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dramatic-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>themselves</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustn't</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that'll</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dummy\n",
       "term_str         \n",
       "themselves      1\n",
       "mustn't         1\n",
       "did             1\n",
       "just            1\n",
       "them            1\n",
       "the             1\n",
       "that'll         1\n",
       "any             1\n",
       "no              1\n",
       "mustn           1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "polished-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exact-broad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>be</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17160</th>\n",
       "      <td>they</td>\n",
       "      <td>3050</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>after</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18874</th>\n",
       "      <td>when</td>\n",
       "      <td>2302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>now</td>\n",
       "      <td>1622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17125</th>\n",
       "      <td>there</td>\n",
       "      <td>1274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>haven</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17403</th>\n",
       "      <td>to</td>\n",
       "      <td>13209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>below</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>myself</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "1799          be   2010    0     1\n",
       "17160       they   3050    0     1\n",
       "675        after    418    0     1\n",
       "18874       when   2302    0     1\n",
       "11488        now   1622    0     1\n",
       "17125      there   1274    0     1\n",
       "8098       haven     19    0     1\n",
       "17403         to  13209    0     1\n",
       "1973       below     22    0     1\n",
       "11177     myself    219    0     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-dinner",
   "metadata": {},
   "source": [
    "### 2. Add Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "satisfied-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "VOCAB['p_stem'] = VOCAB.term_str.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "following-flower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>ait</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>brine</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>brine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17184</th>\n",
       "      <td>think</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>misbehaved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>misbehav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>bessa</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bessa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>reasons</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>rhetoric</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rhetor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>blushd</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>blushd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12940</th>\n",
       "      <td>polyæmons</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>polyæmon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14386</th>\n",
       "      <td>rew</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str    n  num  stop    p_stem\n",
       "term_id                                      \n",
       "747             ait    1    0     0       ait\n",
       "2482          brine    8    0     0     brine\n",
       "17184         think  180    0     0     think\n",
       "10902    misbehaved    1    0     0  misbehav\n",
       "2024          bessa    2    0     0     bessa\n",
       "13867       reasons    3    0     0    reason\n",
       "14398      rhetoric    2    0     0    rhetor\n",
       "2207         blushd    2    0     0    blushd\n",
       "12940     polyæmons    1    0     0  polyæmon\n",
       "14386           rew    2    0     0       rew"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-soccer",
   "metadata": {},
   "source": [
    "### 3. Add pos_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unable-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = TOKEN.groupby(['term_str','pos']).pos.count().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stable-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = VOCAB.reset_index().set_index('term_str')\n",
    "VOCAB['pos_max'] = M.idxmax(1)\n",
    "VOCAB = VOCAB.reset_index().set_index('term_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "electric-fireplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "      <th>pos_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15789</th>\n",
       "      <td>son</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>son</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>man</td>\n",
       "      <td>1263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>man</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17224</th>\n",
       "      <td>thou</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thou</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>hand</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hand</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>house</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hous</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>king</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>king</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>fight</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fight</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17105</th>\n",
       "      <td>thee</td>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thee</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18756</th>\n",
       "      <td>way</td>\n",
       "      <td>632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>way</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17349</th>\n",
       "      <td>till</td>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>till</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8459</th>\n",
       "      <td>home</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14943</th>\n",
       "      <td>sea</td>\n",
       "      <td>558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sea</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>death</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>death</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>father</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>father</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15276</th>\n",
       "      <td>ship</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ship</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>round</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>round</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>head</td>\n",
       "      <td>465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>head</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>heart</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>heart</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>earth</td>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>earth</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>mind</td>\n",
       "      <td>447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mind</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str     n  num  stop  p_stem pos_max\n",
       "term_id                                          \n",
       "15789        son  1762    0     0     son      NN\n",
       "10456        man  1263    0     0     man      NN\n",
       "17224       thou   854    0     0    thou      NN\n",
       "7970        hand   769    0     0    hand      NN\n",
       "8560       house   745    0     0    hous      NN\n",
       "9663        king   689    0     0    king      NN\n",
       "6705       fight   681    0     0   fight      NN\n",
       "17105       thee   667    0     0    thee      NN\n",
       "18756        way   632    0     0     way      NN\n",
       "17349       till   583    0     0    till      NN\n",
       "8459        home   563    0     0    home      NN\n",
       "14943        sea   558    0     0     sea      NN\n",
       "4351       death   555    0     0   death      NN\n",
       "6549      father   547    0     0  father      NN\n",
       "15276       ship   505    0     0    ship      NN\n",
       "14555      round   471    0     0   round      NN\n",
       "8111        head   465    0     0    head      NN\n",
       "8150       heart   460    0     0   heart      NN\n",
       "5415       earth   452    0     0   earth      NN\n",
       "10861       mind   447    0     0    mind      NN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.pos_max == 'NN'].sort_values('n', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-catalyst",
   "metadata": {},
   "source": [
    "## Add F4 vector space representations of the `TOKEN` data\n",
    "\n",
    "The following code chunks create the vector space representations of the `TOKEN` data, including relevant statistics and TFIDF scores. \n",
    "\n",
    "* Code taken from module 5 guide and homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "logical-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_vocab = VOCAB.shape[0]\n",
    "U_vocab = 1/N_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "superb-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()  # Probability\n",
    "VOCAB['s'] = 1 / VOCAB.p              # Surprise\n",
    "VOCAB['i'] = np.log2(VOCAB.s)         # Information\n",
    "VOCAB['h'] = VOCAB.p * VOCAB.i        # Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dominant-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['wlen'] = VOCAB.term_str.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "every-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = VOCAB.set_index('term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "common-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(tokens, vocab, bag, tf_type='n', item_type='term_str', alpha=.4, new_col_suffix=''):\n",
    "    \n",
    "    # Create BOW\n",
    "    BOW = tokens.groupby(bag+[item_type])[item_type].count()\\\n",
    "        .to_frame('n')\n",
    "    BOW['c'] = 1\n",
    "    \n",
    "    # Compute TF\n",
    "    D = BOW.groupby(bag).n\n",
    "    if tf_type == 'n':\n",
    "        BOW['tf'] = BOW.n\n",
    "    elif tf_type == 'sum':\n",
    "        BOW['tf'] = D.apply(lambda x: x / x.sum()) # cp = P(w|d)\n",
    "    elif tf_type == 'l2':\n",
    "        BOW['tf'] = D.apply(lambda x: x / np.sqrt((x**2).sum()))\n",
    "    elif tf_type == 'max':\n",
    "        BOW['tf'] = D.apply(lambda x: alpha + (1-alpha) * (x / x.max()))\n",
    "    elif tf_type == 'log':\n",
    "        BOW['tf'] = D.apply(lambda x: np.log2(1 + x))\n",
    "    elif tf_type == 'sub':\n",
    "        BOW['tf'] = D.apply(lambda x: 1 + np.log2(x))\n",
    "    elif tf_type == 'bool':\n",
    "        BOW['tf'] = BOW.c\n",
    "    elif tf_type == 'bool2':\n",
    "        BOW['tf'] = D.apply(lambda x: 1 / len(x))\n",
    "    \n",
    "    # Normalize TF\n",
    "    \n",
    "    # Compute IDF\n",
    "    vocab['df'] = BOW.groupby('term_str').n.count()\n",
    "    N_docs = len(D.groups)\n",
    "    vocab['idf'] = np.log2(N_docs/vocab.df)\n",
    "    \n",
    "    # Compute TFIDF\n",
    "    BOW['tfidf'] = BOW.tf * vocab.idf\n",
    "    \n",
    "    # Compute aggregate TFIDF\n",
    "    col = 'tfidf_sum' + new_col_suffix\n",
    "    vocab[col] = BOW.groupby(item_type)['tfidf'].sum()\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "taken-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = get_tfidf(TOKEN, VOCAB, bag=DOCS, tf_type='max', new_col_suffix='_doc_max', alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "innocent-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "      <th>wlen</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf_sum_doc_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>4733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>:</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>114.788506</td>\n",
       "      <td>6.842834</td>\n",
       "      <td>0.059613</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>11318.625000</td>\n",
       "      <td>13.466411</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>67911.750000</td>\n",
       "      <td>16.051374</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>271647.000000</td>\n",
       "      <td>18.051374</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ῥα</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ῥα</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ῥοτὸς</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ῥοτὸς</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ῥοᾓ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ῥοᾓ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ῥέω</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ῥέω</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ῥῶγες</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ῥῶγες</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>543294.000000</td>\n",
       "      <td>19.051374</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19733 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             n  num  stop p_stem pos_max         p              s          i  \\\n",
       "term_str                                                                       \n",
       "          4733    0     0              :  0.008712     114.788506   6.842834   \n",
       "1           48    1     0      1      NN  0.000088   11318.625000  13.466411   \n",
       "10           8    1     0     10      JJ  0.000015   67911.750000  16.051374   \n",
       "100          2    1     0    100      CD  0.000004  271647.000000  18.051374   \n",
       "1000         1    1     0   1000      CD  0.000002  543294.000000  19.051374   \n",
       "...        ...  ...   ...    ...     ...       ...            ...        ...   \n",
       "ῥα           1    0     0     ῥα      NN  0.000002  543294.000000  19.051374   \n",
       "ῥοτὸς        1    0     0  ῥοτὸς     NNP  0.000002  543294.000000  19.051374   \n",
       "ῥοᾓ          1    0     0    ῥοᾓ     NNP  0.000002  543294.000000  19.051374   \n",
       "ῥέω          1    0     0    ῥέω     NNP  0.000002  543294.000000  19.051374   \n",
       "ῥῶγες        1    0     0  ῥῶγες      NN  0.000002  543294.000000  19.051374   \n",
       "\n",
       "                 h  wlen  df       idf  tfidf_sum_doc_max  \n",
       "term_str                                                   \n",
       "          0.059613     0   4  0.000000           0.000000  \n",
       "1         0.001190     1   3  0.415037           0.003287  \n",
       "10        0.000236     2   3  0.415037           0.000573  \n",
       "100       0.000066     3   1  2.000000           0.000598  \n",
       "1000      0.000035     4   1  2.000000           0.000299  \n",
       "...            ...   ...  ..       ...                ...  \n",
       "ῥα        0.000035     2   1  2.000000           0.000299  \n",
       "ῥοτὸς     0.000035     5   1  2.000000           0.000361  \n",
       "ῥοᾓ       0.000035     3   1  2.000000           0.000361  \n",
       "ῥέω       0.000035     3   1  2.000000           0.000361  \n",
       "ῥῶγες     0.000035     5   1  2.000000           0.000299  \n",
       "\n",
       "[19733 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "respective-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC.to_csv('{}/DOC.csv'.format(data_out))\n",
    "LIB.to_csv('{}/LIB.csv'.format(data_out))\n",
    "VOCAB.to_csv('{}/VOCAB.csv'.format(data_out))\n",
    "TOKEN.to_csv('{}/TOKEN.csv'.format(data_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-senator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
